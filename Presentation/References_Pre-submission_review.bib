@article{AthEtAl2017,
  title={Forecasting with temporal hierarchies},
  author={Athanasopoulos, George and Hyndman, Rob J and Kourentzes, Nikolaos and Petropoulos, Fotios},
  journal={European Journal of Operational Research},
  volume={262},
  number={1},
  pages={60--74},
  year={2017},
  publisher={Elsevier}
}
@article{AthEtAl2009,
title = "Hierarchical forecasts for Australian domestic tourism",
journal = "International Journal of Forecasting",
volume = "25",
number = "1",
pages = "146 - 166",
year = "2009",
issn = "0169-2070",
doi = "https://doi.org/10.1016/j.ijforecast.2008.07.004",
author = "George Athanasopoulos and Roman A. Ahmed and Rob J. Hyndman",
keywords = "Australia, Exponential smoothing, Hierarchical forecasting, Innovations state space models, Optimal combination forecasts, Top-down method, Tourism demand"
}
@article{Gneiting2006,
abstract = {With the global proliferation of wind power, the need for accurate short-term forecasts of wind resources at wind energy sites is becoming paramount. Regime-switching space-time (RST) models merge meteorological and statistical expertise to obtain accurate and calibrated, fully probabilistic forecasts of wind speed and wind power. The model formulation is parsimonious, yet takes into account all of the salient features of wind speed: alternating atmospheric regimes, temporal and spatial correlation, diurnal and seasonal nonstationarity, conditional heteroscedasticity, and non-Gaussianity. The RST method identifies forecast regimes at a wind energy site and fits a conditional predictive model for each regime. Geographically dispersed meteorological observations in the vicinity of the wind farm are used as off-site predictors. The RST technique was applied to 2-hour-ahead forecasts of hourly average wind speed near the Stateline wind energy center in the U.S. Pacific Northwest. The RST point forecasts and distributional forecasts were accurate, calibrated, and sharp, and they compared favorably with predictions based on state-of-the-art time series techniques. This suggests that quality meteorological data from sites upwind of wind farms can be efficiently used to improve short-term forecasts of wind resources.},
author = {Gneiting, Tilmann and Larson, Kristin and Westrick, Kenneth and Genton, Marc G and Aldrich, Eric},
doi = {10.1198/016214506000000456},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {continuous ranked probability score,minimum continuous ranked probability,predictive distribution,score estimation,spatiotemporal,truncated normal,weather prediction},
number = {475},
pages = {968--979},
title = {{Calibrated Probabilistic Forecasting at the Stateline Wind Energy Center}},
volume = {101},
year = {2006}
}
@article{Wickramasuriya2018,
author = {Wickramasuriya, Shanika L and Athanasopoulos, George and Hyndman, Rob J},
doi = {10.1080/01621459.2018.1448825},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickramasuriya, Athanasopoulos, Hyndman - 2018 - Optimal forecast reconciliation for hierarchical and grouped time series through trace.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Aggregation,Australian tourism,Coherent forecasts,contemporaneous error correlation,forecast combinations,spatial correlations},
pages = {1--45},
publisher = {Taylor {\&} Francis},
title = {{Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization}},
url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1448825},
volume = {1459},
year = {2018}
}
@article{hyndman2017forecasting,
author = {Hyndman, R},
journal = {URL: http://github.com/robjhyndman/forecast},
title = {{forecast: Forecasting Functions for Time Series and Linear Models, R package version 8.0}},
year = {2017}
}
@misc{Kahn1998,
abstract = {Encourages a hybrid approach consisting of top-down and bottom-up sales forecasting. Comparison of the two types of forecasting; Forecasting issues companies face; Data pattern characteristics; Comparisons of mean absolute error across forecast levels.},
author = {Kahn, Kenneth B},
booktitle = {Journal of Business Forecasting Methods {\&} Systems},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kahn - 1998 - Revisiting top-down versus bottom-up forecasting.pdf:pdf},
isbn = {0278-6087},
issn = {02786087},
keywords = {SALES forecasting},
number = {2},
pages = {14},
title = {{Revisiting top-down versus bottom-up forecasting}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=985713{\&}lang=pt-br{\&}site=ehost-live},
volume = {17},
year = {1998}
}
@article{Gneiting2014,
abstract = {Aprobabilistic forecast takes the form of a predictive probability distribution over future quantities or events of interest. Probabilistic forecasting aims to maximize the sharpness of the predictive distributions, subject to calibra- tion, on the basis of the available information set. We formalize and study notions of calibration in a prediction space setting. In practice, probabilis- tic calibration can be checked by examining probability integral transform (PIT) histograms. Proper scoring rules such as the logarithmic score and the continuous ranked probability score serve to assess calibration and sharp- ness simultaneously. As a special case, consistent scoring functions provide decision-theoretically coherent tools for evaluating point forecasts.We em- phasizemethodological links to parametric and nonparametric distributional regression techniques, which attempt to model and to estimate conditional distribution functions; we use the context of statistically postprocessed en- semble forecasts in numerical weather prediction as an example. Through- out, we illustrate concepts and methodologies in data examples. 125},
author = {Gneiting, Tilmann and Katzfuss, Matthias},
doi = {10.1146/annurev-statistics-062713-085831},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Katzfuss - 2014 - Probabilistic Forecasting.pdf:pdf},
isbn = {978-0-8243-3950-0},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {calibration,consistent scoring function,distributional regression,ensemble forecast,proper scoring,rule},
pages = {125--151},
title = {{Probabilistic Forecasting}},
volume = {1},
year = {2014}
}
@article{Vilar2010,
abstract = {The problem of clustering time series is studied for a general class of non-parametric autoregressive models. The dissimilarity between two time series is based on comparing their full forecast densities at a given horizon. In particular, two functional distances are considered: L1 and L 2. As the forecast densities are unknown, they are approximated using a bootstrap procedure that mimics the underlying generating processes without assuming any parametric model for the true autoregressive structure of the series. The estimated forecast densities are then used to construct the dissimilarity matrix and hence to perform clustering. Asymptotic properties of the proposed method are provided and an extensive simulation study is carried out. The results show the good behavior of the procedure for a wide variety of nonlinear autoregressive models and its robustness to non-Gaussian innovations. Finally, the proposed methodology is applied to a real dataset involving economic time series. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Vilar, J. A. and Alonso, A. M. and Vilar, J. M.},
doi = {10.1016/j.csda.2009.02.015},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Non-parametric density forecasts/Time series clustering based on nonparametric multidimensional forecast densities.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
number = {11},
pages = {2850--2865},
publisher = {Elsevier B.V.},
title = {{Non-linear time series clustering based on non-parametric forecast densities}},
url = {http://dx.doi.org/10.1016/j.csda.2009.02.015},
volume = {54},
year = {2010}
}
@article{SCHEUERER2015,
author = {Scheuerer, Michael and Hamill, Thomas M.},
doi = {10.1175/MWR-D-14-00269.1},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Scheuerer, Hamill - 2015 - Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities.pdf:pdf},
journal = {Monthly Weather Review},
number = {4},
pages = {1321--1334},
title = {{Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities *}},
volume = {143},
year = {2015}
}
@article{Gross1990,
abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable.},
author = {Gross, Charles W. and Sohl, Jeffrey E.},
doi = {10.1002/for.3980090304},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gross, Sohl - 1990 - Disaggregation methods to expedite product line forecasting.pdf:pdf},
isbn = {1099-131X},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {Composite root mean square error differential,Disaggregational methods,Forecasting,Product line,Time series analysis},
number = {3},
pages = {233--254},
title = {{Disaggregation methods to expedite product line forecasting}},
volume = {9},
year = {1990}
}
@article{Pinson2012,
author = {Pinson, Pierre},
doi = {10.1002/qj.1873},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinson - 2012 - Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts.pdf:pdf},
journal = {Quarterly Journal of the Royal Meteorological Society},
keywords = {bivariate processes,ensemble prediction,near-,probabilistic calibration,recursive estimation},
pages = {1273--1284},
title = {{Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts}},
volume = {138},
year = {2012}
}
@article{Pinson2009,
abstract = {Short-term (up to 2-3 days ahead) probabilistic forecasts of wind power provide forecast users with a highly valuable information on the uncertainty of expected wind generation. Whatever the type of these probabilistic forecasts, they are produced on a per horizon basis, and hence do not inform on the devel- opment of the forecast uncertainty through forecast series. However, this additional informationmay be paramount for a large class of time-dependent and multi-stage decision-making problems e.g. optimal operation of combined wind-storage systems or multiple-market trading with different gate closures. This issue is addressed here by describing amethod that permits the generation of statistical scenarios of short-termwind generation that accounts for both the interdependence structure of prediction errors and the predictive distributions of wind power production. The method is based on the conversion of series of prediction errors to a multivariate Gaussian random variable, the interdependence structure of which can then be summarized by a unique covariance matrix. Such matrix is recursively estimated in order to accommodate long-term variations in the prediction error characteristics. The quality and interest of the methodology are demonstrated with an application to the test case of a multi-MWwind farm over a period of more than two years. Keywords:},
author = {Pinson, Pierre and Madsen, Henrik and Papaefthymiou, George and Kl{\"{o}}ckl, Bernd},
doi = {10.1002/we.284},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinson et al. - 2009 - From Probabilistic Forecasts to Wind Power Production.pdf:pdf},
issn = {10954244},
journal = {Wind Energy},
keywords = {forecasting,multivariate Gaussian random variable,scenarios,uncertainty,wind power},
number = {1},
pages = {51--62},
title = {{From Probabilistic Forecasts to Wind Power Production}},
volume = {12},
year = {2009}
}
@article{Gneiting2005,
author = {Gneiting, Tilmann and Raftery, Andrian E.},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Raftery - 2005 - Weather{\_}forecasting{\_}with{\_}ensem.PDF.pdf:pdf},
journal = {Science},
pages = {248--249},
title = {{Weather forecasting with ensemble methods}},
volume = {310.5746},
year = {2005}
}
@article{Manzan2008,
abstract = {Interest in density forecasts (as opposed to solely modeling the conditional mean) arises from the possibility of dynamics in higher moments of a time series, as well as in forecasting the probability of future events in some applications. By combining the idea of Markov bootstrapping with that of kernel density estimation, this paper presents a simple non-parametric method for estimating out-of-sample multi-step density forecasts. The paper also considers a host of evaluation tests for examining the dynamic misspecification of estimated density forecasts by targeting autocorrelation, heteroskedasticity and neglected non-linearity. These tests are useful, as a rejection of the tests gives insight into ways to improve a particular forecasting model. In an extensive Monte Carlo analysis involving a range of commonly used linear and non-linear time series processes, the non-parametric method is shown to work reasonably well across the simulated models for a suitable choice of the bandwidth (smoothing parameter). Furthermore, an application of the method to the U.S. Industrial Production series provides multi-step density forecasts that show no sign of dynamic misspecification. {\textcopyright} 2007 International Institute of Forecasters.},
author = {Manzan, Sebastiano and Zerom, Dawit},
doi = {10.1016/j.ijforecast.2007.12.004},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Non-parametric density forecasts/A bootstrap based non parametric forecast density.pdf:pdf},
isbn = {0169-2070},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {Dynamic misspecification,Evaluation,Kernel smoothing,Markov bootstrap,Multi-step density forecasts},
number = {3},
pages = {535--550},
title = {{A bootstrap-based non-parametric forecast density}},
volume = {24},
year = {2008}
}
@article{Nicolau2010,
author = {Nicolau, Jo{\~{a}}o},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Non-parametric density forecasts/Nonparametric density forecast based on time- and state-domain.pdf:pdf},
keywords = {density forecasts,earnings forecast,nonparametric methods,time},
number = {December 2010},
pages = {706--720},
title = {{Nonparametric Density Forecast Based on Time- and State-Domain}},
volume = {720},
year = {2010}
}
@article{Hyndman2011,
abstract = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these "hierarchical time series". They are commonly forecast using either a "bottom-up" or a "top-down" method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
doi = {10.1016/j.csda.2011.03.006},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyndman et al. - 2011 - Optimal combination forecasts for hierarchical time series.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Bottom-up forecasting,Combining forecasts,GLS regression,Hierarchical forecasting,Reconciling forecasts,Top-down forecasting},
number = {9},
pages = {2579--2589},
publisher = {Elsevier B.V.},
title = {{Optimal combination forecasts for hierarchical time series}},
volume = {55},
year = {2011}
}
@article{Fliedner2001,
abstract = {In order to provide the appropriate demand forecast information given various managerial levels and functional disciplines within organizations, reliance on family-based forecasting is increasing. The family-based approach, sometimes referred to as hierarchical forecasting (HF), is based on a strategy of aggregating items into families. HF systems are capable of providing forecasts for items and their respective families. The objectives of HF systems, include improved forecast performance and a reduction in the overall forecasting burden. To date, several studies have offered practical guidelines for the structural design of HF systems. The primary purpose of this paper is to summarize these guidelines. First, an explanation of the HF process is provided. In this explanation, important system parameters and strategic choices, which allow for the custom configuration of HF systems are identified. Second, the relevant family-based forecast research is reviewed. The important issues addressed and the conclusions presented in this research are identified. Third, practical guidelines regarding the use of a HF approach that have been reported in the research literature are clearly delineated. With much still unknown regarding the performance impact of various system parameter and strategic process choices, the paper concludes with suggestions for future research.},
author = {Fliedner, Gene},
doi = {10.1108/02635570110365952},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fliedner - 2001 - Hierarchical forecasting issues and use guidelines.pdf:pdf},
isbn = {1463577001},
issn = {0263-5577},
journal = {Industrial Management {\&} Data Systems},
keywords = {forecasting,hierarchy,product management,time series},
number = {1},
pages = {5--12},
title = {{Hierarchical forecasting: issues and use guidelines}},
volume = {101},
year = {2001}
}
@article{Gneiting2008,
abstract = {We discuss methods for the evaluation of probabilistic predictions of vector-valued quantities, that can take the form of a discrete forecast ensemble or a density forecast. In particular, we propose a multivariate version of the univariate verification rank histogram or Talagrand diagram that can be used to check the calibration of ensemble forecasts. In the case of density forecasts, Box's density ordinate transform provides an attractive alternative. The multivariate energy score generalizes the continuous ranked probability score. It addresses both calibration and sharpness, and can be used to compare deterministic forecasts, ensemble forecasts and density forecasts, using a single loss function that is proper. An application to the University of Washington mesoscale ensemble points at strengths and deficiencies of probabilistic short-range forecasts of surface wind vectors over the North American Pacific Northwest.},
author = {Gneiting, Tilmann and Stanberry, Larissa I. and Grimit, Eric P. and Held, Leonhard and Johnson, Nicholas A.},
doi = {10.1007/s11749-008-0114-x},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2008 - Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of su.pdf:pdf},
isbn = {1174900801186},
issn = {11330686},
journal = {Test},
keywords = {Calibration,Density forecast,Ensemble postprocessing,Exchangeability,Forecast verification,Probability integral transform,Proper scoring rule,Rank histogram,Sharpness},
number = {2},
pages = {211--235},
title = {{Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of surface winds}},
volume = {17},
year = {2008}
}
@article{Dunn1976,
abstract = {Should statistical forecasts be constructed by aggregating data to each level for which forecasts are required or aggregating the forecasts from the lower levels? The relevant literature suggests no general answer. In this study using actual data, forecasts aggregated from lower-level modeling were found best.},
author = {Dunn, D M and Williams, W H and Dechaine, T L},
doi = {10.2307/2285732},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunn, Williams, Dechaine - 1976 - Aggregate Versus Subaggregate Models in Local Area Forecasting.pdf:pdf},
isbn = {0162-1459},
issn = {1537274X},
journal = {Journal of American Statistical Association},
number = {353},
pages = {68--71},
title = {{Aggregate Versus Subaggregate Models in Local Area Forecasting}},
volume = {71},
year = {1976}
}
@article{Szekely2013,
abstract = {Energy distance is a statistical distance between the distributions of random vectors, which characterizes equality of distributions. The name energy derives from Newton's gravitational potential energy, and there is an elegant relation to the notion of potential energy between statistical observations. Energy statistics are functions of distances between statistical observations in metric spaces. Thus even if the observations are complex objects, like functions, one can use their real valued nonnegative distances for inference. Theory and application of energy statistics are discussed and illustrated. Finally, we explore the notion of potential and kinetic energy of goodness-of-fit. {\textcopyright}2013 Elsevier B.V.},
author = {Sz{\'{e}}kely, G{\'{a}}bor J and Rizzo, Maria L},
doi = {10.1016/j.jspi.2013.03.018},
isbn = {03783758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Distance correlation,Distance covariance,Energy distance,Goodness-of-fit,Multivariate independence},
number = {8},
pages = {1249--1272},
publisher = {Elsevier},
title = {{Energy statistics: A class of statistics based on distances}},
url = {http://dx.doi.org/10.1016/j.jspi.2013.03.018},
volume = {143},
year = {2013}
}
@techreport{Pinson2013a,
abstract = {Research on generating and verification of multivariate probabilistic forecasts has gained increased interest over the last few years. Emphasis is placed here on the evaluation of forecast quality with the Energy score, which is based on a quadratic scoring rule. While this score may be seen as appealing since being proper, we show that its discrimination ability may be limited when focusing on the dependence structure of multivariate probabilistic forecasts. For the case of multivariate Gaussian process, a theoretical upper for such discrimination ability is derived and discussed. This limited discrimination ability may eventually get compromised by computational and sampling issues, as dimension increases.},
author = {Pinson, P and Tastu, Julija},
institution = {Technical University of Denmark.},
keywords = {Discrimination,Energy score,Multivariate scenarios BT - Discrimination ability,Probabilistic forecasting,Proper score},
title = {{Discrimination ability of the Energy score}},
year = {2013}
}
@article{Gneiting2005a,
abstract = {Ensemble prediction systems typically show positive spread-error correlation, but they are subject to forecast bias and dispersion errors, and are therefore uncalibrated. This work proposes the use of ensemble model output statistics (EMOS), an easy-to-implement postprocessing technique that addresses both forecast bias and underdispersion and takes into account the spread-skill relationship. The technique is based on multiple linear regression and is akin to the superensemble approach that has traditionally been used for deterministic-style forecasts. The EMOS technique yields probabilistic forecasts that take the form of Gaussian predictive probability density functions (PDFs) for continuous weather variables and can be applied to gridded model output. The EMOS predictive mean is a bias-corrected weighted average of the ensemble member forecasts, with coefficients that can be interpreted in terms of the relative contributions of the member models to the ensemble, and provides a highly competitive deterministic-style forecast. The EMOS predictive variance is a linear function of the ensemble variance. For fitting the EMOS coefficients, the method of minimum continuous ranked probability score (CRPS) estimation is introduced. This technique finds the coefficient values that optimize the CRPS for the training data. The EMOS technique was applied to 48-h forecasts of sea level pressure and surface temperature over the North American Pacific Northwest in spring 2000, using the University of Washington mesoscale ensemble. When compared to the bias-corrected ensemble, deterministic-style EMOS forecasts of sea level pressure had root-mean-square error 9{\%} less and mean absolute error 7{\%} less. The EMOS predictive PDFs were sharp, and much better calibrated than the raw ensemble or the bias-corrected ensemble.},
author = {Gneiting, Tilmann and Raftery, Adrian E. and Westveld, Anton H. and Goldman, Tom},
doi = {10.1175/MWR2904.1},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2005 - Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum CRPS Estimation.pdf:pdf},
issn = {0027-0644},
journal = {Monthly Weather Review},
number = {5},
pages = {1098--1118},
title = {{Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum CRPS Estimation}},
volume = {133},
year = {2005}
}
@article{Hyndman2016,
abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
author = {Hyndman, Rob J and Lee, Alan J and Wang, Earo},
doi = {10.1016/j.csda.2015.11.007},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Combining forecasts,Grouped time series,Hierarchical time series,Reconciling forecasts,Weighted least squares},
pages = {16--32},
publisher = {Elsevier B.V.},
title = {{Fast computation of reconciled forecasts for hierarchical and grouped time series}},
url = {http://dx.doi.org/10.1016/j.csda.2015.11.007},
volume = {97},
year = {2016}
}
@article{Gel2004,
abstract = {Probabilistic weather forecasting consists of finding a joint probability distribution for future weather quantities or events. It is typically done by using a numerical weather prediction model, perturbing the inputs to the model in various ways, and running the model for each perturbed set of inputs. The result is then viewed as an ensemble of forecasts, taken to be a sample from the joint probability distribution of the future weather quantities of interest. This is typically not feasible for mesoscale weather prediction carried out locally by organizations without the vast data and computing resources of national weather centers. Instead, we propose a simpler method that breaks with much previous practice by perturbing the outputs, or deterministic forecasts, from the model. Forecast errors are modeled using a geostatistical model, and ensemble members are generated by simulating realizations of the geostatistical model. The method is applied to 48-hour mesoscale forecasts of temperature in the North ...},
author = {Gel, Yulia and Raftery, Adrian E and Gneiting, Tilmann},
doi = {10.1198/016214504000000872},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gel, Raftery, Gneiting - 2004 - Calibrated Probabilistic Mesoscale Weather Field Forecasting.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {empirical calibration,ensemble forecast,geostatistical simulation,probabilistic weather prediction},
number = {July},
pages = {575--583},
title = {{Calibrated Probabilistic Mesoscale Weather Field Forecasting}},
volume = {99},
year = {2004}
}
@unpublished{Jeon2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1808.02635v1},
author = {Jeon, Jooyoung and Panagiotelis, Anastasios and Petropoulos, Fotios},
eprint = {arXiv:1808.02635v1},
file = {:C$\backslash$:/Users/Puwasala/Desktop/Reconciliation of probabilistic forecasts with an application to wind power.pdf:pdf},
keywords = {aggregation,cross-validation,forecasting,renewable energy,temporal hierarchies},
title = {{Reconciliation of probabilistic forecasts with an application to wind power}},
year = {2018}
}
@book{VanErven2015a,
abstract = {In hierarchical time series (HTS) forecasting, the hierarchical relation be- tween multiple time series is exploited to make better forecasts. This hierarchical relation implies one or more aggregate consistency constraints that the series are known to satisfy. Many existing approaches, like for example bottom-up or top- down forecasting, therefore attempt to achieve this goal in a way that guarantees that the forecasts will also be aggregate consistent. We propose to split the problem of HTS into two independent steps: first one comes up with the best possible fore- casts for the time series without worrying about aggregate consistency; and then a reconciliation procedure is used to make the forecasts aggregate consistent. We introduce a Game-Theoretically OPtimal (GTOP) reconciliation method, which is guaranteed to only improve any given set of forecasts. This opens up new possibil- ities for constructing the forecasts. For example, it is not necessary to assume that bottom-level forecasts are unbiased, and aggregate forecasts may be constructed by regressing both on bottom-level forecasts and on other covariates that may only be available at the aggregate level. We illustrate the benefits of our approach both on simulated data and on real electricity consumption data.},
author = {{Van Erven}, Tim and Cugliari, Jairo},
booktitle = {Spinger Lecture Notes in Statistics. Paris: Springer,},
doi = {10.1007/978-3-319-18732-7_15},
editor = {Antoniadis, A and Brossat, X and Poggi, J M},
isbn = {9783319187310},
issn = {21977186},
pages = {297--317},
title = {{Game-Theoretically Optimal reconciliation of contemporaneous hierarchical time series forecasts}},
year = {2014}
}
@article{Yao2006,
abstract = {Abstract. We provide a direct proof for consistency and asymptotic normality of Gaussian maximum likelihood estimators for causal and invertible autoregressive moving-average (ARMA) time series models, which were initially established by Hannan [Journal of Applied Probability (1973) vol. 10, pp. 130–145] via the asymptotic properties of a Whittle's estimator. This also paves the way to establish similar results for spatial processes presented in the follow-up article by Yao and Brockwell [Bernoulli (2006) in press].},
author = {Yao, Qiwei and Brockwell, Peter J},
doi = {10.1111/j.1467-9892.2006.00492.x},
isbn = {1467-9892},
issn = {01439782},
journal = {Journal of Time Series Analysis},
keywords = {ARMA time series models,Asymptotic normality,Consistency,Gaussian maximum likelihood estimator,Innovation algorithm,Martingale difference,Prewhitening},
number = {6},
pages = {857--875},
title = {{Gaussian maximum likelihood estimation for ARMA models. I. Time series}},
volume = {27},
year = {2006}
}
@article{Schwarzkopf1988,
author = {Schwarzkopf, Albert B.1 and Tersine, Richard J.1 and Morris, John S.2},
doi = {10.1080/00207548808947995},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwarzkopf, Tersine, Morris - 1988 - Top-down versus bottom-up forecasting strategies.pdf:pdf},
issn = {0020-7543},
journal = {nternational Journal of Production Research},
number = {11},
pages = {1833},
title = {{Top-down versus bottom-up forecasting strategies.}},
volume = {26},
year = {1988}
}
@article{Gneiting2007,
abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G?=F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster tomake careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed.We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
author = {Gneiting, Tilmann and Raftery, Adrian E},
doi = {10.1198/016214506000001437},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Estimation.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {bayes factor,bregman divergence,brier score,coherent,continuous ranked probability score,cross-validation,distribution,entropy,kernel score,loss function,minimum contrast estimation,negative definite function,prediction interval,predictive,quantile forecast,scoring rule,skill score,strictly proper,utility function},
number = {477},
pages = {359--378},
title = {{Strictly Proper Scoring Rules, Prediction, and Estimation}},
volume = {102},
year = {2007}
}
@article{Lapide1998,
author = {Lapide, Larry},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lapide - 1998 - A simple view of top-down vs bottom-up forecasting.pdf.pdf:pdf},
journal = {Journal of Business Forecasting Methods {\&} Systems},
pages = {28--31},
title = {{A simple view of top-down vs bottom-up forecasting.pdf}},
volume = {17},
year = {1998}
}
@article{BenTaieb2017,
abstract = {Smart electricity meters are currently deployed in millions of households to collect detailed individual electricity consumption data. Compared to traditional electricity data based on aggregated consumption, smart meter data are much more volatile and less predictable. There is a need within the energy industry for probabilistic forecasts of household electricity consumption to quantify the uncertainty of future electricity demand, in order to undertake appropriate planning of generation and distribution. We propose to estimate an additive quantile regression model for a set of quantiles of the future distribution using a boosting procedure. By doing so, we can benefit from flexible and interpretable models which include an automatic variable selection. We compare our approach with three benchmark methods on both aggregated and disaggregated scales using a smart meter dataset collected from 3639 households in Ireland at 30-minute intervals over a period of 1.5 years. The empirical results demonstrate that our approach based on quantile regression provides better forecast accuracy for disaggregated demand while the traditional approach based on a normality assumption (possibly after an appropriate Box- Cox transformation) is a better approximation for aggregated demand. These results are particularly useful since more energy data will become available at the disaggregated level in the future. I. INTRODUCTION T HE energy sector has been changing dramatically, notably due to the integration of renewable energy sources, in an effort to reduce our dependency on fossil fuels and achieve a better sustainable future. With the growing amount of data from energy systems, there is a need for utilities to quantify the uncertainty in future generation and demand, especially for wind power [1], solar power [2] and electricity demand [3]. In particular, accurate probabilistic forecasts for electricity demand are critical for electric utilities in many operational and planning tasks. Electricity load is often represented as the aggregated load across many households (e.g. at the city level). There is also a rich literature on forecasting the average aggregated electricity load; i.e. in forecasting the mean of the future demand distribution. These forecasts are often conditional on a number of predictor variables such as calendar and temperature variables. Many models have been considered S. BenTaieb is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia, and the Monash Business School, Clayton, VIC 3800, Australia (e-mails: souhaib.bentaieb@monash.edu). R. Huser is with the King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia (e-mail: raphael.huser@kaust.edu.sa). R. J. Hyndman is with the Monash Business School, Clayton, VIC 3800, Australia (e-mail: rob.hyndman@monash.edu). M. G. Genton is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia (e-mail: marc.genton@kaust.edu.sa). for},
author = {{Ben Taieb}, Souhaib and Huser, Raphael and Hyndman, Rob J and Genton, Marc G},
doi = {10.1109/TSG.2016.2527820},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben Taieb et al. - 2016 - Forecasting uncertainty in electricity smart meter data by boosting additive quantile regression.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Probabilistic load forecasting,gradient boosting,quantile regression,smart meters},
number = {5},
pages = {2448--2455},
title = {{Forecasting uncertainty in electricity smart meter data by boosting additive quantile regression}},
volume = {7},
year = {2017}
}
@article{McSharry2005,
abstract = {Adequate capacity planning requires accurate forecasts of the future magnitude and timing of peak electricity demand. Electricity demand is affected by the day of the week, seasonal variations, holiday periods, feast days, and the weather. A model that provides probabilistic forecasts of both magnitude and timing for lead times of one year is presented. This model is capable of capturing the main sources of variation in demand and uses simulated weather time series, including temperature, wind speed, and luminosity, for producing probabilistic forecasts of future peak demand. Having access to such probabilistic forecasts provides a means of assessing the uncertainty in the forecasts and can lead to improved decision making and better risk management. {\&}copy; 2005 IEEE.},
author = {McSharry, Patrick E. and Bouwman, Sonja and Bloemhof, Gabri{\"{e}}l},
doi = {10.1109/TPWRS.2005.846071},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McSharry, Bouwman, Bloemhof - 2005 - Probabilistic forecasts of the magnitude and timing of peak electricity demand.pdf:pdf},
isbn = {0885-8950},
issn = {08858950},
journal = {IEEE Transactions on Power Systems},
keywords = {Load forecasting,Load management,Management decision making,Power demand,Power generation peaking capacity,Power system planning,Simulation,Temperature,Time series},
number = {2},
pages = {1166--1172},
title = {{Probabilistic forecasts of the magnitude and timing of peak electricity demand}},
volume = {20},
year = {2005}
}

@article{capistran2010multi,
  title={Multi-horizon inflation forecasts using disaggregated data},
  author={Capistr{\'a}n, Carlos and Constandse, Christian and Ramos-Francia, Manuel},
  journal={Economic Modelling},
  volume={27},
  number={3},
  pages={666--677},
  year={2010},
  publisher={Elsevier}
}

@phdthesis{weiss2018essays,
  title={Essays in Hierarchical Time Series Forecasting and Forecast Combination},
  author={Weiss, Christoph},
  year={2018},
  school={University of Cambridge}
}
