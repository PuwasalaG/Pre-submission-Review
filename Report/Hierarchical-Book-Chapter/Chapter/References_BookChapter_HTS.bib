@article{CogEtAl2005,
  title={Bayesian fan charts for {UK} inflation: Forecasting and sources of uncertainty in an evolving monetary system},
  author={Cogley, Timothy and Morozov, Sergei and Sargent, Thomas J},
  journal={Journal of Economic Dynamics and Control},
  volume={29},
  number={11},
  pages={1893--1925},
  year={2005},
  publisher={Elsevier}
}
@article{SmiVah2016,
  title={Asymmetric forecast densities for us macroeconomic variables from a gaussian copula model of cross-sectional and serial dependence},
  author={Smith, Michael S and Vahey, Shaun P},
  journal={Journal of Business \& Economic Statistics},
  volume={34},
  number={3},
  pages={416--434},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{BilEtAl2013,
  title={Time-varying combinations of predictive densities using nonlinear filtering},
  author={Billio, Monica and Casarin, Roberto and Ravazzolo, Francesco and Van Dijk, Herman K},
  journal={Journal of Econometrics},
  volume={177},
  number={2},
  pages={213--232},
  year={2013},
  publisher={Elsevier}
}
@article{ClaRav2015,
  title={Macroeconomic forecasting performance under alternative specifications of time-varying volatility},
  author={Clark, Todd E and Ravazzolo, Francesco},
  journal={Journal of Applied Econometrics},
  volume={30},
  number={4},
  pages={551--575},
  year={2015},
  publisher={Wiley Online Library}
}
@article{CarEtAl2015,
  title={Realtime nowcasting with a {Bayesian} mixed frequency model with stochastic volatility},
  author={Carriero, Andrea and Clark, Todd E and Marcellino, Massimiliano},
  journal={Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume={178},
  number={4},
  pages={837--862},
  year={2015},
  publisher={Wiley Online Library}
}
@article{GewAmi2010,
  title={Comparing and evaluating {Bayesian} predictive distributions of asset returns},
  author={Geweke, John and Amisano, Gianni},
  journal={International Journal of Forecasting},
  volume={26},
  number={2},
  pages={216--230},
  year={2010},
  publisher={Elsevier}
}


@article{Vilar2013,
abstract = {The problem of clustering time series is studied for a general class of non-parametric autoregressive models. The dissimilarity between two time series is based on comparing their full forecast densities at a given horizon. In particular, two functional distances are considered: L1 and L 2. As the forecast densities are unknown, they are approximated using a bootstrap procedure that mimics the underlying generating processes without assuming any parametric model for the true autoregressive structure of the series. The estimated forecast densities are then used to construct the dissimilarity matrix and hence to perform clustering. Asymptotic properties of the proposed method are provided and an extensive simulation study is carried out. The results show the good behavior of the procedure for a wide variety of nonlinear autoregressive models and its robustness to non-Gaussian innovations. Finally, the proposed methodology is applied to a real dataset involving economic time series. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Vilar, Jos{\'{e}} A. and Vilar, J. A.},
doi = {10.1214/13-EJS800},
journal = {Electronic Journal of Statistics},
keywords = {Bootstrap,Kernel estimation,Multidimensional forecast density,Principal components analysis,Time series clustering},
number = {1},
pages = {1019--1046},
title = {Time series clustering based on nonparametric multidimensional forecast densities},
volume = {7},
year = {2013}
}
@article{Mircetic2017,
author = {Mir{\v{c}}eti{\'{c}}, Dejan and Nikoli{\v{c}}i{\'{c}}, Svetlana and Stojanovi{\'{c}}, Durdica and Maslari{\'{c}}, Marinko},
doi = {10.1016/j.trpro.2017.03.026},
journal = {Transportation Research Procedia},
keywords = {beverage supply chain,hierarchical forecasting,modified top down approach,time series},
pages = {193--202},
title = {Modified top down approach for hierarchical forecasting in a beverage supply chain},
volume = {22},
year = {2017}
}
@unpublished{Jeon2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1808.02635v1},
author = {Jeon, Jooyoung and Panagiotelis, Anastasios and Petropoulos, Fotios},
eprint = {arXiv:1808.02635v1},
keywords = {aggregation,cross-validation,forecasting,renewable energy,temporal hierarchies},
title = {Reconciliation of probabilistic forecasts with an application to wind power},
year = {2018}
}
@article{Taieb2017,
author = {Taieb, Souhaib Ben and Taylor, James W and Hyndman, Rob J},
keywords = {aggregates of time series,butions,empirical copulas,forecast combinations,predictive distri-,smart meters},
pages = {1--30},
title = {Hierarchical Probabilistic Forecasting of Electricity Demand with Smart Meter Data},
year = {2017}
}
@article{Nicolau2010,
author = {Nicolau, Jo{\~{a}}o},
keywords = {density forecasts,earnings forecast,nonparametric methods,time},
number = {December 2010},
pages = {706--720},
title = {Nonparametric Density Forecast Based on Time- and State-Domain},
volume = {720},
year = {2010}
}
@article{Manzan2008,
abstract = {Interest in density forecasts (as opposed to solely modeling the conditional mean) arises from the possibility of dynamics in higher moments of a time series, as well as in forecasting the probability of future events in some applications. By combining the idea of Markov bootstrapping with that of kernel density estimation, this paper presents a simple non-parametric method for estimating out-of-sample multi-step density forecasts. The paper also considers a host of evaluation tests for examining the dynamic misspecification of estimated density forecasts by targeting autocorrelation, heteroskedasticity and neglected non-linearity. These tests are useful, as a rejection of the tests gives insight into ways to improve a particular forecasting model. In an extensive Monte Carlo analysis involving a range of commonly used linear and non-linear time series processes, the non-parametric method is shown to work reasonably well across the simulated models for a suitable choice of the bandwidth (smoothing parameter). Furthermore, an application of the method to the U.S. Industrial Production series provides multi-step density forecasts that show no sign of dynamic misspecification. {\textcopyright} 2007 International Institute of Forecasters.},
author = {Manzan, Sebastiano and Zerom, Dawit},
doi = {10.1016/j.ijforecast.2007.12.004},
journal = {International Journal of Forecasting},
keywords = {Dynamic misspecification,Evaluation,Kernel smoothing,Markov bootstrap,Multi-step density forecasts},
number = {3},
pages = {535--550},
title = {A bootstrap-based non-parametric forecast density},
volume = {24},
year = {2008}
}
@article{Vilar2010,
abstract = {The problem of clustering time series is studied for a general class of non-parametric autoregressive models. The dissimilarity between two time series is based on comparing their full forecast densities at a given horizon. In particular, two functional distances are considered: L1 and L 2. As the forecast densities are unknown, they are approximated using a bootstrap procedure that mimics the underlying generating processes without assuming any parametric model for the true autoregressive structure of the series. The estimated forecast densities are then used to construct the dissimilarity matrix and hence to perform clustering. Asymptotic properties of the proposed method are provided and an extensive simulation study is carried out. The results show the good behavior of the procedure for a wide variety of nonlinear autoregressive models and its robustness to non-Gaussian innovations. Finally, the proposed methodology is applied to a real dataset involving economic time series. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Vilar, J. A. and Alonso, A. M. and Vilar, J. M.},
doi = {10.1016/j.csda.2009.02.015},
journal = {Computational Statistics and Data Analysis},
number = {11},
pages = {2850--2865},
publisher = {Elsevier B.V.},
title = {Non-linear time series clustering based on non-parametric forecast densities},
volume = {54},
year = {2010}
}
@article{BenTaieb2017,
abstract = {Smart electricity meters are currently deployed in millions of households to collect detailed individual electricity consumption data. Compared to traditional electricity data based on aggregated consumption, smart meter data are much more volatile and less predictable. There is a need within the energy industry for probabilistic forecasts of household electricity consumption to quantify the uncertainty of future electricity demand, in order to undertake appropriate planning of generation and distribution. We propose to estimate an additive quantile regression model for a set of quantiles of the future distribution using a boosting procedure. By doing so, we can benefit from flexible and interpretable models which include an automatic variable selection. We compare our approach with three benchmark methods on both aggregated and disaggregated scales using a smart meter dataset collected from 3639 households in Ireland at 30-minute intervals over a period of 1.5 years. The empirical results demonstrate that our approach based on quantile regression provides better forecast accuracy for disaggregated demand while the traditional approach based on a normality assumption (possibly after an appropriate Box- Cox transformation) is a better approximation for aggregated demand. These results are particularly useful since more energy data will become available at the disaggregated level in the future. I. INTRODUCTION T HE energy sector has been changing dramatically, notably due to the integration of renewable energy sources, in an effort to reduce our dependency on fossil fuels and achieve a better sustainable future. With the growing amount of data from energy systems, there is a need for utilities to quantify the uncertainty in future generation and demand, especially for wind power [1], solar power [2] and electricity demand [3]. In particular, accurate probabilistic forecasts for electricity demand are critical for electric utilities in many operational and planning tasks. Electricity load is often represented as the aggregated load across many households (e.g. at the city level). There is also a rich literature on forecasting the average aggregated electricity load; i.e. in forecasting the mean of the future demand distribution. These forecasts are often conditional on a number of predictor variables such as calendar and temperature variables. Many models have been considered S. BenTaieb is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia, and the Monash Business School, Clayton, VIC 3800, Australia (e-mails: souhaib.bentaieb@monash.edu). R. Huser is with the King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia (e-mail: raphael.huser@kaust.edu.sa). R. J. Hyndman is with the Monash Business School, Clayton, VIC 3800, Australia (e-mail: rob.hyndman@monash.edu). M. G. Genton is with the King Abdullah University of Science and Tech- nology (KAUST), Thuwal, Saudi Arabia (e-mail: marc.genton@kaust.edu.sa). for},
author = {{Ben Taieb}, Souhaib and Huser, Raphael and Hyndman, Rob J and Genton, Marc G},
doi = {10.1109/TSG.2016.2527820},
journal = {IEEE Transactions on Smart Grid},
keywords = {Probabilistic load forecasting,gradient boosting,quantile regression,smart meters},
number = {5},
pages = {2448--2455},
title = {Forecasting uncertainty in electricity smart meter data by boosting additive quantile regression},
volume = {7},
year = {2017}
}
@article{McSharry2005,
abstract = {Adequate capacity planning requires accurate forecasts of the future magnitude and timing of peak electricity demand. Electricity demand is affected by the day of the week, seasonal variations, holiday periods, feast days, and the weather. A model that provides probabilistic forecasts of both magnitude and timing for lead times of one year is presented. This model is capable of capturing the main sources of variation in demand and uses simulated weather time series, including temperature, wind speed, and luminosity, for producing probabilistic forecasts of future peak demand. Having access to such probabilistic forecasts provides a means of assessing the uncertainty in the forecasts and can lead to improved decision making and better risk management. {\&}copy; 2005 IEEE.},
author = {McSharry, Patrick E and Bouwman, Sonja and Bloemhof, Gabri{\"{e}}l},
doi = {10.1109/TPWRS.2005.846071},
journal = {IEEE Transactions on Power Systems},
keywords = {Load forecasting,Load management,Management decision making,Power demand,Power generation peaking capacity,Power system planning,Simulation,Temperature,Time series},
number = {2},
pages = {1166--1172},
title = {Probabilistic forecasts of the magnitude and timing of peak electricity demand},
volume = {20},
year = {2005}
}
@article{Hyndman2016,
abstract = {It is shown that the least squares approach to reconciling hierarchical time series forecasts can be extended to much more general collections of time series with aggregation constraints. The constraints arise due to the need for forecasts of collections of time series to add up in the same way as the observed time series. It is also shown that the computations involved can be handled efficiently by exploiting the structure of the associated design matrix, or by using sparse matrix routines. The proposed algorithms make forecast reconciliation feasible in business applications involving very large numbers of time series.},
author = {Hyndman, Rob J. and Lee, Alan J. and Wang, Earo},
doi = {10.1016/j.csda.2015.11.007},
journal = {Computational Statistics and Data Analysis},
keywords = {Combining forecasts,Grouped time series,Hierarchical time series,Reconciling forecasts,Weighted least squares},
pages = {16--32},
publisher = {Elsevier B.V.},
title = {Fast computation of reconciled forecasts for hierarchical and grouped time series},
volume = {97},
year = {2016}
}
@article{Schafer2005,
abstract = {{\textless}p{\textgreater}Inferring large-scale covariance matrices from sparse genomic data is an ubiquitous problem in bioinformatics. Clearly, the widely used standard covariance and correlation estimators are ill-suited for this purpose. As statistically efficient and computationally fast alternative we propose a novel shrinkage covariance estimator that exploits the Ledoit-Wolf (2003) lemma for analytic calculation of the optimal shrinkage intensity.Subsequently, we apply this improved covariance estimator (which has guaranteed minimum mean squared error, is well-conditioned, and is always positive definite even for small sample sizes) to the problem of inferring large-scale gene association networks. We show that it performs very favorably compared to competing approaches both in simulations as well as in application to real expression data.{\textless}/p{\textgreater}},
author = {Sch{\"{a}}fer, Juliane and Strimmer, Korbinian},
journal = {Statistical Applications in Genetics and Molecular Biology},
number = {1},
pmid = {16646851},
title = {A Shrinkage Approach to Large-Scale Covariance Matrix Estimation and Implications for Functional Genomics},
volume = {4},
year = {2005},
pages = {1--30}
}
@article{Hall2007,
abstract = {This paper brings together two important but hitherto largely unrelated areas of the forecasting literature, density forecasting and forecast combination. It proposes a practical data-driven approach to the direct combination of density forecasts by taking a weighted linear combination of the competing density forecasts. The combination weights are chosen to minimize the 'distance', as measured by the Kullback-Leibler information criterion, between the forecasted and true but unknown density. We explain how this minimization both can and should be achieved but leave theoretical analysis to future research. Comparisons with the optimal combination of point forecasts are made. An application to simple time-series density forecasts and two widely used published density forecasts for U.K. inflation, namely the Bank of England and NIESR "fan" charts, illustrates that combination can but need not always help. {\textcopyright} 2006 International Institute of Forecasters.},
author = {Hall, Stephen G. and Mitchell, James},
doi = {10.1016/j.ijforecast.2006.08.001},
journal = {International Journal of Forecasting},
keywords = {Combining forecasts,Density forecasts,Evaluating forecasts,Inflation forecasting,Uncertainty},
number = {1},
pages = {1--13},
title = {Combining density forecasts},
volume = {23},
year = {2007}
}
@article{Diebold1999,
abstract = {The first of two exploratory studies investigated the conflict management approaches of 310 South Korean leaders. Each recalled the most recent dispute they had encountered either between two subordinates or between a subordinate and a person outside the group (i.e., an outsider).Subsequently, they reported the techniques used to mange the dispute. As predicted, the leaders were more assertive in managing subordinate-subordinate conflicts. Unexpectedly, they also pressed their own subordinates quite forcefully in the subordinate-outsider disputes. The second study investigated subordinates' interventions in their leaders' disputes. In these conflicts, subordinates adopted a low-key shuttle diplomacy; meeting separately with the parties, listening to their opinions, transmitting these to the other side, and calling for each side's empathy and understanding.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Diebold, Francis X. and Hahn, Jinyong and Tay, Anthony S.},
doi = {10.1086/250095},
eprint = {arXiv:1011.1669v3},
journal = {The Review of Economics and Statistics},
number = {4},
pages = {661--673},
pmid = {17979356},
title = {Multivariate Density Forecast Evaluation and Calibration in Fi nancial Risk Management: High-Frequency Returns on Foreign Exchange},
volume = {81},
year = {1999}
}
@article{SCHEUERER2015,
author = {Scheuerer, Michael and Hamill, Thomas M.},
doi = {10.1175/MWR-D-14-00269.1},
journal = {Monthly Weather Review},
number = {4},
pages = {1321--1334},
title = {Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities},
volume = {143},
year = {2015}
}
@article{Szekely2013,
abstract = {Energy distance is a statistical distance between the distributions of random vectors, which characterizes equality of distributions. The name energy derives from Newton's gravitational potential energy, and there is an elegant relation to the notion of potential energy between statistical observations. Energy statistics are functions of distances between statistical observations in metric spaces. Thus even if the observations are complex objects, like functions, one can use their real valued nonnegative distances for inference. Theory and application of energy statistics are discussed and illustrated. Finally, we explore the notion of potential and kinetic energy of goodness-of-fit. {\textcopyright} 2013 Elsevier B.V.},
author = {Sz{\'{e}}kely, G{\'{a}}bor J. and Rizzo, Maria L.},
doi = {10.1016/j.jspi.2013.03.018},
journal = {Journal of Statistical Planning and Inference},
keywords = {Distance correlation,Distance covariance,Energy distance,Goodness-of-fit,Multivariate independence},
number = {8},
pages = {1249--1272},
publisher = {Elsevier},
title = {Energy statistics: A class of statistics based on distances},
volume = {143},
year = {2013}
}
@techreport{Pinson2013a,
abstract = {Research on generating and verification of multivariate probabilistic forecasts has gained increased interest over the last few years. Emphasis is placed here on the evaluation of forecast quality with the Energy score, which is based on a quadratic scoring rule. While this score may be seen as appealing since being proper, we show that its discrimination ability may be limited when focusing on the dependence structure of multivariate probabilistic forecasts. For the case of multivariate Gaussian process, a theoretical upper for such discrimination ability is derived and discussed. This limited discrimination ability may eventually get compromised by computational and sampling issues, as dimension increases.},
author = {Pinson, P and Tastu, Julija},
institution = {Technical University of Denmark.},
keywords = {Discrimination,Energy score,Multivariate scenarios BT - Discrimination ability,Probabilistic forecasting,Proper score},
title = {Discrimination ability of the Energy score},
year = {2013}
}
@article{GneRaf2005,
abstract = {Traditional weather forecasting has been built on a foundation of deterministic modeling--start with initial conditions, put them into a supercomputer model, and end up with a prediction about future weather. But as Gneiting and Raftery discuss in their Perspective, a new approach--ensemble forecasting--was introduced in the early 1990s. In this method, up to 100 different computer runs, each with slightly different starting conditions or model assumptions, are combined into a weather forecast. In concert with statistical techniques, ensembles can provide accurate statements about the uncertainty in daily and seasonal forecasting. The challenge now is to improve the modeling, statistical analysis, and visualization technologies for disseminating the ensemble results.},
author = {Gneiting, T.},
doi = {10.1126/science.1115255},
journal = {Science},
number = {5746},
pages = {248--249},
pmid = {16224011},
title = {Weather Forecasting with Ensemble Methods},
volume = {310},
year = {2005}
}
@article{Pinson2009,
abstract = {Short-term (up to 2-3 days ahead) probabilistic forecasts of wind power provide forecast users with a highly valuable information on the uncertainty of expected wind generation. Whatever the type of these probabilistic forecasts, they are produced on a per horizon basis, and hence do not inform on the devel- opment of the forecast uncertainty through forecast series. However, this additional informationmay be paramount for a large class of time-dependent and multi-stage decision-making problems e.g. optimal operation of combined wind-storage systems or multiple-market trading with different gate closures. This issue is addressed here by describing amethod that permits the generation of statistical scenarios of short-termwind generation that accounts for both the interdependence structure of prediction errors and the predictive distributions of wind power production. The method is based on the conversion of series of prediction errors to a multivariate Gaussian random variable, the interdependence structure of which can then be summarized by a unique covariance matrix. Such matrix is recursively estimated in order to accommodate long-term variations in the prediction error characteristics. The quality and interest of the methodology are demonstrated with an application to the test case of a multi-MWwind farm over a period of more than two years. Keywords:},
author = {Pinson, Pierre and Madsen, Henrik and Papaefthymiou, George and Kl{\"{o}}ckl, Bernd},
doi = {10.1002/we.284},
journal = {Wind Energy},
keywords = {forecasting,multivariate Gaussian random variable,scenarios,uncertainty,wind power},
number = {1},
pages = {51--62},
title = {From Probabilistic Forecasts to Wind Power Production},
volume = {12},
year = {2009}
}
@article{Gneiting2005a,
abstract = {Ensemble prediction systems typically show positive spread-error correlation, but they are subject to forecast bias and dispersion errors, and are therefore uncalibrated. This work proposes the use of ensemble model output statistics (EMOS), an easy-to-implement postprocessing technique that addresses both forecast bias and underdispersion and takes into account the spread-skill relationship. The technique is based on multiple linear regression and is akin to the superensemble approach that has traditionally been used for deterministic-style forecasts. The EMOS technique yields probabilistic forecasts that take the form of Gaussian predictive probability density functions (PDFs) for continuous weather variables and can be applied to gridded model output. The EMOS predictive mean is a bias-corrected weighted average of the ensemble member forecasts, with coefficients that can be interpreted in terms of the relative contributions of the member models to the ensemble, and provides a highly competitive deterministic-style forecast. The EMOS predictive variance is a linear function of the ensemble variance. For fitting the EMOS coefficients, the method of minimum continuous ranked probability score (CRPS) estimation is introduced. This technique finds the coefficient values that optimize the CRPS for the training data. The EMOS technique was applied to 48-h forecasts of sea level pressure and surface temperature over the North American Pacific Northwest in spring 2000, using the University of Washington mesoscale ensemble. When compared to the bias-corrected ensemble, deterministic-style EMOS forecasts of sea level pressure had root-mean-square error 9{\%} less and mean absolute error 7{\%} less. The EMOS predictive PDFs were sharp, and much better calibrated than the raw ensemble or the bias-corrected ensemble.},
author = {Gneiting, Tilmann and Raftery, Adrian E. and Westveld, Anton H. and Goldman, Tom},
doi = {10.1175/MWR2904.1},
journal = {Monthly Weather Review},
number = {5},
pages = {1098--1118},
title = {Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum {CRPS} Estimation},
volume = {133},
year = {2005}
}
@article{Gneiting2006,
abstract = {With the global proliferation of wind power, the need for accurate short-term forecasts of wind resources at wind energy sites is becoming paramount. Regime-switching space-time (RST) models merge meteorological and statistical expertise to obtain accurate and calibrated, fully probabilistic forecasts of wind speed and wind power. The model formulation is parsimonious, yet takes into account all of the salient features of wind speed: alternating atmospheric regimes, temporal and spatial correlation, diurnal and seasonal nonstationarity, conditional heteroscedasticity, and non-Gaussianity. The RST method identifies forecast regimes at a wind energy site and fits a conditional predictive model for each regime. Geographically dispersed meteorological observations in the vicinity of the wind farm are used as off-site predictors. The RST technique was applied to 2-hour-ahead forecasts of hourly average wind speed near the Stateline wind energy center in the U.S. Pacific Northwest. The RST point forecasts and distributional forecasts were accurate, calibrated, and sharp, and they compared favorably with predictions based on state-of-the-art time series techniques. This suggests that quality meteorological data from sites upwind of wind farms can be efficiently used to improve short-term forecasts of wind resources.},
author = {Gneiting, Tilmann and Larson, Kristin and Westrick, Kenneth and Genton, Marc G and Aldrich, Eric},
doi = {10.1198/016214506000000456},
journal = {Journal of the American Statistical Association},
keywords = {continuous ranked probability score,minimum continuous ranked probability,predictive distribution,score estimation,spatiotemporal,truncated normal,weather prediction},
number = {475},
pages = {968--979},
title = {Calibrated Probabilistic Forecasting at the Stateline Wind Energy Center},
volume = {101},
year = {2006}
}
@article{Gel2004,
abstract = {Probabilistic weather forecasting consists of finding a joint probability distribution for future weather quantities or events. It is typically done by using a numerical weather prediction model, perturbing the inputs to the model in various ways, and running the model for each perturbed set of inputs. The result is then viewed as an ensemble of forecasts, taken to be a sample from the joint probability distribution of the future weather quantities of interest. This is typically not feasible for mesoscale weather prediction carried out locally by organizations without the vast data and computing resources of national weather centers. Instead, we propose a simpler method that breaks with much previous practice by perturbing the outputs, or deterministic forecasts, from the model. Forecast errors are modeled using a geostatistical model, and ensemble members are generated by simulating realizations of the geostatistical model. The method is applied to 48-hour mesoscale forecasts of temperature in the North ...},
author = {Gel, Yulia and Raftery, Adrian E and Gneiting, Tilmann},
doi = {10.1198/016214504000000872},
journal = {Journal of the American Statistical Association},
keywords = {empirical calibration,ensemble forecast,geostatistical simulation,probabilistic weather prediction},
number = {July},
pages = {575--583},
title = {Calibrated Probabilistic Mesoscale Weather Field Forecasting},
volume = {99},
year = {2004}
}
@article{Pinson2013,
abstract = {Renewable energy sources, especially wind energy, are to play a larger role in providing electricity to industrial and domestic consumers. This is already the case today for a number of European countries, closely followed by the US and high growth countries, for example, Brazil, India and China. There exist a number of techno- logical, environmental and political challenges linked to supplement- ing existing electricity generation capacities with wind energy. Here, mathematicians and statisticians could make a substantial contribu- tion at the interface of meteorology and decision-making, in connec- tion with the generation of forecasts tailored to the various operational decision problems involved. Indeed, while wind energy may be seen as an environmentally friendly source of energy, full benefits from its us- age can only be obtained if one is able to accommodate its variability and limited predictability. Based on a short presentation of its phys- ical basics, the importance of considering wind power generation as a stochastic process is motivated. After describing representative op- erational decision-making problems for both market participants and system operators, it is underlined that forecasts should be issued in a probabilistic framework. Even though, eventually, the forecaster may only communicate single-valued predictions. The existing approaches to wind power forecasting are subsequently described, with focus on single-valued predictions, predictive marginal densities and space–time trajectories. Upcoming challenges related to generating improved and new types of forecasts, as well as their verification and value to forecast users, are finally discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6471v1},
author = {Pinson, Pierre},
doi = {10.1214/13-STS445},
eprint = {arXiv:1312.6471v1},
isbn = {0883-4237},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,decision-making,electricity markets,forecast,forecast verification,gaussian copula,linear and nonlinear regression,parametric and nonparametric,parametric and nonparametric predictive densities,power systems operations,predictive densities,quantile,quantile regression,regression,renewable energy,space,space-time trajectories,stochas-,stochastic optimization,time trajectories,verification},
number = {4},
pages = {564--585},
title = {Wind Energy: Forecasting Challenges for Its Operational Management},
volume = {28},
year = {2013}
}
@article{Tay2000,
abstract = {A density forecast of the realization of a random variable at some future time is an estimate of the probability distribution of the possible future values of that variable. This article presents a selective survey of applications of density forecasting in macroeconomics and finance, and discusses some issues concerning the production, presentation, and evaluation of density forecasts. Copyright (C) 2000 John Wiley {\&} Sons, Ltd.},
author = {Tay, Anthony S. and Wallis, Kenneth F.},
doi = {10.1002/9780470996430.ch3},
journal = {Journal of Forecasting},
keywords = {Financial forecasts,density forecasts,economic forecasts,forecast evaluation,probability distributions},
pages = {124--143},
title = {Density forecasting: A survey},
volume = {19},
year = {2000}
}
@article{Abramson1995,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Abramson, Bruce and Clemen, Robert},
doi = {10.1016/0169-2070(94)02000-F},
eprint = {arXiv:1011.1669v3},
journal = {International Journal of Forecasting},
number = {1},
pages = {1--4},
pmid = {25246403},
title = {Probability forecasting},
volume = {11},
year = {1995}
}
@misc{Kahn1998,
abstract = {Encourages a hybrid approach consisting of top-down and bottom-up sales forecasting. Comparison of the two types of forecasting; Forecasting issues companies face; Data pattern characteristics; Comparisons of mean absolute error across forecast levels.},
author = {Kahn, Kenneth B},
booktitle = {Journal of Business Forecasting Methods {\&} Systems},
keywords = {SALES forecasting},
number = {2},
pages = {14},
title = {Revisiting top-down versus bottom-up forecasting},
volume = {17},
year = {1998}
}
@article{Schwarzkopf1988,
author = {Schwarzkopf, Albert B.1 and Tersine, Richard J.1 and Morris, John S.2},
doi = {10.1080/00207548808947995},
journal = {nternational Journal of Production Research},
number = {11},
pages = {1833},
title = {Top-down versus bottom-up forecasting strategies.},
volume = {26},
year = {1988}
}
@misc{Crespi2008,
author = {Crespi},
title = {Top Down vs Bottom Up Methodologies},
year = {2008}
}
@article{Lapide1998,
author = {Lapide, Larry},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lapide - 1998 - A simple view of top-down vs bottom-up forecasting.pdf.pdf:pdf},
journal = {Journal of Business Forecasting Methods {\&} Systems},
pages = {28--31},
title = {A simple view of top-down vs bottom-up forecasting},
volume = {17},
year = {1998}
}
@article{Fliedner2001,
abstract = {In order to provide the appropriate demand forecast information given various managerial levels and functional disciplines within organizations, reliance on family-based forecasting is increasing. The family-based approach, sometimes referred to as hierarchical forecasting (HF), is based on a strategy of aggregating items into families. HF systems are capable of providing forecasts for items and their respective families. The objectives of HF systems, include improved forecast performance and a reduction in the overall forecasting burden. To date, several studies have offered practical guidelines for the structural design of HF systems. The primary purpose of this paper is to summarize these guidelines. First, an explanation of the HF process is provided. In this explanation, important system parameters and strategic choices, which allow for the custom configuration of HF systems are identified. Second, the relevant family-based forecast research is reviewed. The important issues addressed and the conclusions presented in this research are identified. Third, practical guidelines regarding the use of a HF approach that have been reported in the research literature are clearly delineated. With much still unknown regarding the performance impact of various system parameter and strategic process choices, the paper concludes with suggestions for future research.},
author = {Fliedner, Gene},
doi = {10.1108/02635570110365952},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fliedner - 2001 - Hierarchical forecasting issues and use guidelines.pdf:pdf},
isbn = {1463577001},
issn = {0263-5577},
journal = {Industrial Management {\&} Data Systems},
keywords = {forecasting,hierarchy,product management,time series},
number = {1},
pages = {5--12},
title = {Hierarchical forecasting: issues and use guidelines},
volume = {101},
year = {2001}
}
@article{Dunn1976,
abstract = {Should statistical forecasts be constructed by aggregating data to each level for which forecasts are required or aggregating the forecasts from the lower levels? The relevant literature suggests no general answer. In this study using actual data, forecasts aggregated from lower-level modeling were found best.},
author = {Dunn, D M and Williams, W H and Dechaine, T L},
doi = {10.2307/2285732},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunn, Williams, Dechaine - 1976 - Aggregate Versus Subaggregate Models in Local Area Forecasting.pdf:pdf},
isbn = {0162-1459},
issn = {1537274X},
journal = {Journal of American Statistical Association},
number = {353},
pages = {68--71},
title = {Aggregate Versus Subaggregate Models in Local Area Forecasting},
volume = {71},
year = {1976}
}
@article{Gross1990,
abstract = {This paper addresses the issue of forecasting individual items within a product line; where each line includes several independent but closely related products. The purpose of the research was to reduce the overall forecasting burden by developing and assessing schemes of disaggregating forecasts of a total product line to the related individual items. Measures were developed to determine appropriate disaggregated methodologies and to compare the forecast accuracy of individual product forecasts versus disaggregated totals. Several of the procedures used were based upon extensions of the combination of forecast research and applied to disaggregations of total forecasts of product lines. The objective was to identify situations when it was advantageous to produce disaggregated forecasts, and if advantageous, which method of disaggregation to utilize. This involved identification of the general conceptual characteristics within a set of product line data that might cause a disaggregation method to produce relatively accurate forecasts. These conceptual characteristics provided guidelines for forecasters on how to select a disaggregation method and under what conditions a particular method is applicable.},
author = {Gross, Charles W. and Sohl, Jeffrey E.},
doi = {10.1002/for.3980090304},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gross, Sohl - 1990 - Disaggregation methods to expedite product line forecasting.pdf:pdf},
isbn = {1099-131X},
issn = {1099131X},
journal = {Journal of Forecasting},
keywords = {Composite root mean square error differential,Disaggregational methods,Forecasting,Product line,Time series analysis},
number = {3},
pages = {233--254},
title = {Disaggregation methods to expedite product line forecasting},
volume = {9},
year = {1990}
}
@inproceedings{Sagaert2017,
author = {Sagaert, Yves R and Vuyst, Stijn De and Kourentzes, Nikolaos and Aghezzaf, El-houssaine},
booktitle = {IESM Conference},
pages = {75--79},
title = {The impact of macroeconomic leading indicators for tactical sales forecasting on {SKU} inventory management},
year = {2017}
}
@techreport{GamEtAl2018,
author = {Gamakumara, Puwasala and Panagiotelis, Anastasios and Athanasopoulos, George and Hyndman, Rob J},
institution = {Monash University Econometrics \& Business Statistics},
type = {Working paper},
number = {11/18},
title = {Probabilisitic Forecasts in Hierarchical Time Series},
year = {2018}
}
@article{Shang2017a,
abstract = {Mortality rates are often disaggregated by different attributes, such as sex, state, education, religion or ethnicity. Forecasting mortality rates at the national and sub-national levels plays an important role in making social policies associated with the national and sub-national levels. However, base forecasts at the sub-national levels may not add up to the forecasts at the national level. To address this issue, we consider the problem of reconciling mortality rate forecasts from the viewpoint of grouped time-series forecasting methods (Hyndman et al., 2011). A bottom-up method and an optimal combination method are applied to produce point forecasts of infant mortality rates that are aggregated appropriately across the different levels of a hierarchy. We extend these two methods by considering the reconciliation of interval forecasts through a bootstrap procedure. Using the regional infant mortality rates in Australia, we investigate the one-step-ahead to 20-step-ahead point and interval forecast accuracies among the independent and these two grouped time-series forecasting methods. The proposed methods are shown to be useful for reconciling point and interval forecasts of demographic rates at the national and sub-national levels, and would be beneficial for government policy decisions regarding the allocations of current and future resources at both the national and sub-national levels.},
archivePrefix = {arXiv},
arxivId = {1608.08718},
author = {Shang, Han Lin},
doi = {10.1007/s11113-016-9413-1},
eprint = {1608.08718},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Hierarchical-Book-Chapter/Literature/Probabilistic forecasting/Reconciling forecasts of infant mortality rates at national and sub-national levels  Grouped time-series methods.pdf:pdf},
issn = {15737829},
journal = {Population Research and Policy Review},
keywords = {Australian infant mortality rates,Bottom-up forecasts,Hierarchical forecasting,Optimal combination,Reconciling forecasts},
number = {1},
pages = {55--84},
publisher = {Springer Netherlands},
title = {{Reconciling Forecasts of Infant Mortality Rates at National and Sub-National Levels: Grouped Time-Series Methods}},
volume = {36},
year = {2017}
}
@article{Gneiting2014,
abstract = {Aprobabilistic forecast takes the form of a predictive probability distribution over future quantities or events of interest. Probabilistic forecasting aims to maximize the sharpness of the predictive distributions, subject to calibra- tion, on the basis of the available information set. We formalize and study notions of calibration in a prediction space setting. In practice, probabilis- tic calibration can be checked by examining probability integral transform (PIT) histograms. Proper scoring rules such as the logarithmic score and the continuous ranked probability score serve to assess calibration and sharp- ness simultaneously. As a special case, consistent scoring functions provide decision-theoretically coherent tools for evaluating point forecasts.We em- phasizemethodological links to parametric and nonparametric distributional regression techniques, which attempt to model and to estimate conditional distribution functions; we use the context of statistically postprocessed en- semble forecasts in numerical weather prediction as an example. Through- out, we illustrate concepts and methodologies in data examples. 125},
author = {Gneiting, Tilmann and Katzfuss, Matthias},
doi = {10.1146/annurev-statistics-062713-085831},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Katzfuss - 2014 - Probabilistic Forecasting.pdf:pdf},
isbn = {978-0-8243-3950-0},
issn = {2326-8298},
journal = {Annual Review of Statistics and Its Application},
keywords = {calibration,consistent scoring function,distributional regression,ensemble forecast,proper scoring,rule},
pages = {125--151},
title = {Probabilistic Forecasting},
volume = {1},
year = {2014}
}
@article{Gneiting2008,
abstract = {We discuss methods for the evaluation of probabilistic predictions of vector-valued quantities, that can take the form of a discrete forecast ensemble or a density forecast. In particular, we propose a multivariate version of the univariate verification rank histogram or Talagrand diagram that can be used to check the calibration of ensemble forecasts. In the case of density forecasts, Box's density ordinate transform provides an attractive alternative. The multivariate energy score generalizes the continuous ranked probability score. It addresses both calibration and sharpness, and can be used to compare deterministic forecasts, ensemble forecasts and density forecasts, using a single loss function that is proper. An application to the University of Washington mesoscale ensemble points at strengths and deficiencies of probabilistic short-range forecasts of surface wind vectors over the North American Pacific Northwest.},
author = {Gneiting, Tilmann and Stanberry, Larissa I. and Grimit, Eric P. and Held, Leonhard and Johnson, Nicholas A.},
doi = {10.1007/s11749-008-0114-x},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting et al. - 2008 - Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of su.pdf:pdf},
isbn = {1174900801186},
issn = {11330686},
journal = {Test},
keywords = {Calibration,Density forecast,Ensemble postprocessing,Exchangeability,Forecast verification,Probability integral transform,Proper scoring rule,Rank histogram,Sharpness},
number = {2},
pages = {211--235},
title = {{Assessing probabilistic forecasts of multivariate quantities, with an application to ensemble predictions of surface winds}},
volume = {17},
year = {2008}
}
@article{Gneiting2007,
abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distribution F if he or she issues the probabilistic forecast F, rather than G?=F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster tomake careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed.We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
author = {Gneiting, Tilmann and Raftery, Adrian E},
doi = {10.1198/016214506000001437},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gneiting, Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Estimation.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {bayes factor,bregman divergence,brier score,coherent,continuous ranked probability score,cross-validation,distribution,entropy,kernel score,loss function,minimum contrast estimation,negative definite function,prediction interval,predictive,quantile forecast,scoring rule,skill score,strictly proper,utility function},
number = {477},
pages = {359--378},
title = {{Strictly Proper Scoring Rules, Prediction, and Estimation}},
volume = {102},
year = {2007}
}
@article{Jordan2017a,
abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The scoringRules package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
archivePrefix = {arXiv},
arxivId = {1709.04743},
author = {Jordan, Alexander and Kr{\"{u}}ger, Fabian and Lerch, Sebastian},
eprint = {1709.04743},
file = {:C$\backslash$:/Puwasala/PhD{\_}Monash/Research/Second year/Literature review/Evaluating probabilistic forecasts/scoringRules{\_}r.package{\_}article.pdf:pdf},
title = {{Evaluating probabilistic forecasts with the R package scoringRules}},
year = {2017}
}
@article{Pinson2012,
author = {Pinson, Pierre},
doi = {10.1002/qj.1873},
file = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinson - 2012 - Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts.pdf:pdf},
journal = {Quarterly Journal of the Royal Meteorological Society},
keywords = {bivariate processes,ensemble prediction,near-,probabilistic calibration,recursive estimation},
pages = {1273--1284},
title = {{Adaptive calibration of {\$}(u, v){\$}-wind ensemble forecasts}},
volume = {138},
year = {2012}
}

@phdthesis{weiss2018essays,
  title={Essays in Hierarchical Time Series Forecasting and Forecast Combination},
  author={Weiss, Christoph},
  year={2018},
  school={University of Cambridge}
}

@phdthesis{gamakumara2019phd,
	title={Probabilistic Forecasts in Hierarchical Time Series},
	author={Gamakumara, Puwasala},
	year={2019},
	school={Monash University}
}

@article{ZelMon1971,
author = {Zellner, Arnold and Montmarquette, Claude},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Zellner, Montmarquette - 1971 - A Study of Some Aspects of Temporal Aggregation Problems in Econometric Analyses.pdf:pdf},
journal = {The Review of Economics and Statistics},
number = {4},
pages = {335--342},
title = {A Study of Some Aspects of Temporal Aggregation Problems in Econometric Analyses},
volume = {53},
year = {1971}
}
@article{AmeWu1972,
archivePrefix = {arXiv},
arxivId = {0026},
author = {Amemiya, Takeshi and Wu, Roland Y.},
eprint = {0026},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Amemiya, Wu - 1972 - The Effect of Aggregation on Prediction in the Autoregressive model.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {339},
pages = {628--632},
title = {The Effect of Aggregation on Prediction in the Autoregressive model},
volume = {67},
year = {1972}
}
@article{Tia1972,
archivePrefix = {arXiv},
arxivId = {0027},
author = {Tiao, G C},
eprint = {0027},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Tiao - 1972 - Asymptotic behaviour of temporal aggregates of time series.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {525--531},
title = {Asymptotic behaviour of temporal aggregates of time series},
volume = {59},
year = {1972}
}
@article{Bre1973,
author = {Brewer, K.R.W.},
doi = {10.1016/0304-4076(73)90015-8},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Brewer - 1973 - Some consequences of temporal aggregation and systematic sampling for ARMA and ARMAX models.pdf:pdf},
isbn = {0304-4076},
issn = {03044076},
journal = {Journal of Econometrics},
number = {2},
pages = {133--154},
title = {Some consequences of temporal aggregation and systematic sampling for {ARMA} and {ARMAX} models},
volume = {1},
year = {1973}
}
@article{Hot1993,
abstract = {Assume that the observed series follows an ARIMA process, and that the forecaster is only interested in predicting aggregated values. In this case the aggregate series also follows an ARIMA process and the prediction could be done using either the disaggregate or the aggregate models. We derive the approximate expected values of the estimates of the model coefficients and of the innovation variances in the presence of a single additive outlier. The approximations are also checked through simulations. Our conclusion is that the approximation is good, provided the size of the series is not too small, and that the additive outlier can have a stronger effect on the disaggregate model than on the aggregate model. An empirical analysis is presented using the international airline passengers series.},
author = {Hotta, Luiz Koodi},
doi = {10.1016/0169-2070(93)90056-S},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Hotta - 1993 - The effect of additive outliers on the estimates from aggregated and disaggregated ARIMA models.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
number = {1},
pages = {85--93},
title = {The effect of additive outliers on the estimates from aggregated and disaggregated {ARIMA} models},
volume = {9},
year = {1993}
}
@article{AthEtAl2017,
abstract = {This paper introduces the concept of Temporal Hierarchies for time series forecasting. A temporal hierarchy can be constructed for any time series by means of non-overlapping temporal aggregation. Predictions constructed at all aggregation levels are combined with the proposed framework to result in temporally reconciled, accurate and robust forecasts. The implied com- bination mitigates modelling uncertainty, while the reconciled nature of the forecasts results in a unified prediction that supports aligned decisions at different planning horizons: from short- term operational up to long-term strategic planning. The proposed methodology is independent of forecasting models. It can embed high level managerial forecasts that incorporate complex and unstructured information with lower level statistical forecasts. Our results show that fore- casting with temporal hierarchies increases accuracy over conventional forecasting, particularly under increased modelling uncertainty. We discuss organisational implications of the temporally reconciled forecasts using a case study of Accident {\&} Emergency departments.},
author = {Athanasopoulos, George and Hyndman, Rob J and Kourentzes, Nikolaos and Petropoulos, Fotios},
file = {:C$\backslash$:/Users/gathana/Dropbox (Personal)/PDFs/Athanasopoulos et al. - 2017 - Forecasting with Temporal Hierarchies.pdf:pdf},
journal = {European Journal of Operational Research},
keywords = {forecast,hierarchical forecasting,reconciliation,temporal aggregation},
pages = {60--74},
title = {Forecasting with Temporal Hierarchies},
volume = {262},
year = {2017}
}
@article{HotCar1993,
annote = {Arheio:31},
author = {Hotta, L. K. and {Cardoso Neto}, J.},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Hotta, Cardoso Neto - 1993 - The effect of aggregation on prediction in autoregressive integrated moving-average models.pdf:pdf},
journal = {Journal of Time Series Analysis},
keywords = {aggregate arima models,efficiency in predicting aggregate,prediction of aggregate series,series},
number = {3},
pages = {261--269},
title = {{The effect of aggregation on prediction in autoregressive integrated moving-average models}},
volume = {14},
year = {1993}
}
@article{Mar1999,
author = {Marcellino, Massimiliano},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Marcellino - 1999 - Some Consequences of Temporal Aggregation in Empirical Analysis.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
number = {1},
pages = {129--136},
title = {Some Consequences of Temporal Aggregation in Empirical Analysis},
volume = {17},
year = {1999}
}
@article{SilEtAl2008,
archivePrefix = {arXiv},
arxivId = {0016},
author = {Silvestrini, Andrea and Salto, Matteo and Moulin, Laurent and Veredas, David},
doi = {10.1007/s00181-007-0132-7},
eprint = {0016},
journal = {Empirical Economics},
number = {3},
pages = {493--524},
title = {{Monitoring and forecasting annual public deficit every month: the case of France}},
volume = {34},
year = {2008}
}
@article{RosSea1995,
author = {Rossana, R.J. and Seater, J.J.},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Rossana, Seater - 1995 - Temporal aggregation and economic times series.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
number = {4},
pages = {441--451},
title = {{Temporal aggregation and economic times series}},
volume = {13},
year = {1995}
}
@article{NijPal1990,
annote = {Arheio:30},
author = {Nijman, Theo E and Palm, Franz C},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Nijman, Palm - 1990 - Disaggregate Sampling in Predictive Models.pdf:pdf},
journal = {Journal of Business {\&} Economic Statistics},
keywords = {arma,disaggregate sampling,models,prediction},
number = {4},
pages = {405--415},
title = {Disaggregate Sampling in Predictive Models},
volume = {8},
year = {1990}
}
@article{AndEtAl2011,
author = {Andrawis, Robert R. and Atiya, Amir F. and El-Shishiny, Hisham},
doi = {10.1016/j.ijforecast.2010.05.019},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Andrawis, Atiya, El-Shishiny - 2011 - Combination of long term and short term forecasts, with application to tourism demand forecasting.pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
keywords = {bayesian forecasting,exponential,forecast combination,forecasting tourism in egypt,holt,s model,smoothing,time series forecasting,tourism demand,tourism forecasting},
number = {3},
pages = {870--886},
publisher = {Elsevier B.V.},
title = {{Combination of long term and short term forecasts, with application to tourism demand forecasting}},
volume = {27},
year = {2011}
}
@article{KouEtAl2014,
annote = {Arheio:34},
author = {Kourentzes, Nikolaos and Petropoulos, Fotios and Trapero, Juan R.},
doi = {10.1016/j.ijforecast.2013.09.006},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Kourentzes, Petropoulos, Trapero - 2014 - Improving forecasting by estimating time series structural components across multiple frequ(2).pdf:pdf},
issn = {01692070},
journal = {International Journal of Forecasting},
number = {2},
pages = {291--302},
publisher = {Elsevier B.V.},
title = {{Improving forecasting by estimating time series structural components across multiple frequencies}},
volume = {30},
year = {2014}
}
@article{PanEtAl2019,
abstract = {JEL classification: C52, C53, C55 Macroeconomic forecasting for Australia using a large number of predictors Abstract A popular approach to forecasting macroeconomic variables is to utilize a large number of predictors. Several regularization and shrinkage methods can be used to exploit such high-dimensional datasets, and have been shown to improve forecast accuracy for the US economy. To assess whether similar results hold for economies with different characteristics, an Australian dataset containing observations on 151 aggregate and disaggregate economic series as well as 185 international variables, is introduced. An extensive empirical study is carried out investigating forecasts at different horizons, using a variety of methods and with information sets containing an increasing number of predictors. In contrast to other countries the results show that it is difficult to forecast Australian key macroeconomic variables more accurately than some simple benchmarks. In line with other studies we also find that there is little to no improvement in forecast accuracy when the number of predictors is expanded beyond 20â€“40 variables and international factors do not seem to help.},
author = {Panagiotelis, Anastasios and Athanasopoulos, George and Hyndman, Rob J and Jiang, Bin and Vahid, Farshid},
file = {:C$\backslash$:/Users/Setup Account/Dropbox (Personal)/PDFs/Panagiotelis et al. - 2019 - Macroeconomic forecasting for Australia using a large number of predictors.pdf:pdf},
journal = {Interantional Journal of Forecasting},
keywords = {Bayesian VAR,bagging,dynamic factor model,least angular regres-sion,regularization,ridge regression,shrinkage},
title = {{Macroeconomic forecasting for Australia using a large number of predictors}},
number = {forthcoming},
year = {2019}
}
@book{HynAth2018,
author = {Hyndman, R J and Athanasopoulos, G.},
publisher = {OTexts},
title = {Forecasting: Principles and Practice},
year = {2018},
url = {https://OTexts.com/fpp2}
}
@unpublished{AthEtAl2019,
author = {Athanasopoulos, George and Steel, Tom and Weatherburn, Don},
institution = {Monash University},
title = {Forecasting prison numbers: A grouped time series approach},
year = {2019}
}
@article{VilPed2018,
abstract = {Time series forecasting plays an important role in many decision support systems, also in those related to the management of supply chains. Forecast accuracy is, therefore, essential to optimise the efficiency of any supply chain. One aspect that is often overlooked is the fact that sales of many products within an organization are assembled as complex hierarchies with different levels of aggregation. Very often forecasts are produced regardless of such structure, though forecasting accuracy may be improved by taking it into account. In this paper, an approach for hierarchical time series forecasting based on State Space modelling is proposed. Previous developments provide solutions to the hierarchical forecasting problem by algebra manipulations based on forecasts produced by independent models for each time series involved in the hierarchy. The solutions produce optimal reconciled forecasts for each individual forecast horizon, but the link along time that is implied by the dynamics of the models is completely ignored. Therefore, the novel approach in this paper improves upon past research at least in two key points. Firstly, the algebra is already encoded in the State Space system and the Kalman Filter algorithm, giving an elegant and clean solution to the problem. Secondly, the State Space approach is optimal both across the hierarchy, as expected, but also along time, something missing in past developments. The approach is assessed by comparing its forecasting performance to the existing methods, through simulations and using real data of a Spanish grocery retailer.},
author = {Villegas, Marco A. and Pedregal, Diego J.},
doi = {10.1016/j.dss.2018.08.003},
journal = {Decision Support Systems},
keywords = {Decision support system,Forecasting,Hierarchical forecasting,Reconciliation,State Space},
pages = {29--36},
title = {Supply chain decision support systems based on a novel hierarchical forecasting approach},
volume = {114},
year = {2018}
}
@article{ZhaDon2018,
author = {Zhang, Yao and Dong, Jiaojiao},
doi = {10.1109/TPWRS.2018.2868175},
file = {:C$\backslash$:/Users/gathana/Dropbox (Personal)/PDFs/Zhang, Dong - 2019 - Least Squares-based Optimal Reconciliation Method for Hierarchical Forecasts of Wind Power Generation.pdf:pdf},
issn = {08858950},
journal = {IEEE Transactions on Power Systems},
keywords = {Aggregates,Bottom-up forecasts,Forecasting,Indexes,Time series analysis,Wind farms,Wind forecasting,Wind power generation,combining forecasts,hier-archical forecasting,least squares regression,top-down forecasts,very short-term forecasting},
publisher = {IEEE},
title = {Least Squares-based Optimal Reconciliation Method for Hierarchical Forecasts of Wind Power Generation},
number = {forthcoming},
year = {2019}
}
@article{YagEtAl2019,
abstract = {When forecasting hierarchical photovoltaic (PV) power generation in a region and/or over several forecast horizons, reconciliation is needed to ensure the lower-level forecasts add up exactly to the upper-level forecasts. Previously in “Reconciling solar forecasts: Geographical hierarchy” [Sol. Energy 146 (2017) 276–286] and “Reconciling solar forecasts: Temporal hierarchy” [Sol. Energy 158 (2017) 332–346], forecast reconciliation has been demonstrated for geographical and temporal hierarchies, separately. This article follows such frameworks and extends the reconciliation to spatio-temporal cases. More specifically, sequential reconciliation is used for operational day-ahead forecasting of 318 PV systems in California. It is shown that by using sequential reconciliation, aggregate-consistent forecasts can be obtained across both the geographical and temporal hierarchies. In addition, the forecast accuracy can be further improved from that of the single-hierarchy cases.},
author = {Yagli, Gokhan Mert and Yang, Dazhi and Srinivasan, Dipti},
doi = {10.1016/j.solener.2018.12.075},
file = {:C$\backslash$:/Users/gathana/Dropbox (Personal)/PDFs/Yagli, Yang, Srinivasan - 2019 - Reconciling solar forecasts Sequential reconciliation.pdf:pdf},
issn = {0038092X},
journal = {Solar Energy},
keywords = {Forecast reconciliation,Numerical weather prediction,Operational forecasting},
pages = {391--397},
title = {Reconciling solar forecasts: Sequential reconciliation},
volume = {179},
year = {2019}
}
@article{YanEtAl2017,
abstract = {To integrate solar energy into the electricity grid reliably and efficiently, different forecasting techniques are used to produce forecasts at various forecast horizons using data of different levels of aggregation. For example, power generated by distributed photovoltaics (PV) can be disaggregated in a geographical hierarchy into transmission zones, distribution nodes, PV plants, subsystems and inverters; forecasts are required at all of these levels to facilitate different power system operations and power plant management. Due to the different information sets visible to different players in the hierarchy, such as PV plant owners and independent system operators, the forecasts produced at different aggregation levels are often not optimal. Furthermore, these forecasts are aggregate inconsistent, i.e., forecasts made using data collected at lower levels do not add up exactly to the forecasts made using higher level data. In this paper, the state-of-the-art forecast reconciliation techniques are explored. By minimizing the trace of forecast error covariance matrix, the base forecasts obtained across the hierarchy can be optimally reconciled. The reconciled forecasts not only aggregate consistently, and thus lead to collaborative decision making, but also improve the base forecasts at each level significantly. The merit of the reconciliation framework goes to the fact that it does not require any additional information other than those base forecasts. Furthermore, forecast improvements are independent of the base forecasting methods. In other words, once the base forecasts are generated with our favorite methods, the reconciliation will most likely improve those forecasts further. The reconciliation techniques can be applied to a variety of hierarchies with different forecast horizons. The empirical part of this work considers two examples, namely, an NWP-based day-ahead forecast reconciliation over 318 simulated PV plants in the state of California, and a spatio-temporal statistical 1-min-ahead forecast reconciliation over 17 irradiance sensors on the Oahu Island, Hawaii. It is shown that reconciliation benefits both the gird operators and PV system owners by bringing more accurate forecasts, and thus motivates information sharing in an electricity grid.},
author = {Yang, Dazhi and Quan, Hao and Disfani, Vahid R. and Liu, Licheng},
doi = {10.1016/j.solener.2017.02.010},
journal = {Solar Energy},
keywords = {Forecasting,Hierarchical reconciliation,Numerical weather prediction,Spatio-temporal forecasting},
pages = {276--286},
title = {Reconciling solar forecasts: Geographical hierarchy},
volume = {146},
year = {2017}
}

@article{capistran2010multi,
  title={Multi-horizon inflation forecasts using disaggregated data},
  author={Capistr{\'a}n, Carlos and Constandse, Christian and Ramos-Francia, Manuel},
  journal={Economic Modelling},
  volume={27},
  number={3},
  pages={666--677},
  year={2010},
  publisher={Elsevier}
}
@Article{AthEtAl2009,
  author   = {Athanasopoulos, George and Ahmed, Roman A. and Hyndman, Rob J.},
  title    = {Hierarchical forecasts for {Australian} domestic tourism},
  journal  = {International Journal of Forecasting},
  year     = {2009},
  volume   = {25},
  number   = {1},
  pages    = {146--166},
  abstract = {In this paper we explore the hierarchical nature of tourism demand time series and produce short-term forecasts for Australian domestic tourism. The data and forecasts are organized in a hierarchy based on disaggregating the data according to geographical regions and purposes of travel. We consider five approaches to hierarchical forecasting: two variations of the top-down approach, the bottom-up method, a newly proposed top-down approach where top-level forecasts are disaggregated according to the forecasted proportions of lower level series, and a recently proposed optimal combination approach. Our forecast performance evaluation shows that the top-down approach based on forecast proportions and the optimal combination method perform best for the tourism hierarchies we consider. By applying these methods, we produce detailed forecasts of the Australian domestic tourism market. {\textcopyright} 2008 International Institute of Forecasters.},
  doi      = {10.1016/j.ijforecast.2008.07.004},
  keywords = {Australia,Exponential smoothing,Hierarchical forecasting,Innovations state space models,Optimal combination forecasts,Top-down method,Tourism demand},
  type     = {Working paper},
}

@Article{ShaHyn2017,
  author        = {Shang, Han Lin and Hyndman, Rob J.},
  title         = {Grouped Functional Time Series Forecasting: An Application to Age-Specific Mortality Rates},
  journal       = {Journal of Computational and Graphical Statistics},
  year          = {2017},
  volume        = {26},
  number        = {2},
  pages         = {330--343},
  issn          = {15372715},
  abstract      = {Age-specific mortality rates are often disaggregated by different attributes, such as sex, state and ethnicity. Forecasting age-specific mortality rates at the national and sub-national levels plays an important role in developing social policy. However, independent forecasts at the sub-national levels may not add up to the forecasts at the national level. To address this issue, we consider reconciling forecasts of age-specific mortality rates, extending the methods of Hyndman et al. (2011) to functional time series, where age is considered as a continuum. The grouped functional time series methods are used to produce point forecasts of mortality rates that are aggregated appropriately across different disaggregation factors. For evaluating forecast uncertainty, we propose a bootstrap method for reconciling interval forecasts. Using the regional age-specific mortality rates in Japan, obtained from the Japanese Mortality Database, we investigate the one- to ten-step-ahead point and interval forecast accuracies between the independent and grouped functional time series forecasting methods. The proposed methods are shown to be useful for reconciling forecasts of age-specific mortality rates at the national and sub-national levels. They also enjoy improved forecast accuracy averaged over different disaggregation factors. Supplemental materials for the article are available online.},
  archiveprefix = {arXiv},
  arxivid       = {1609.04222},
  doi           = {10.1080/10618600.2016.1237877},
  eprint        = {1609.04222},
  file          = {:C$\backslash$:/Users/gathana/Dropbox (Personal)/PDFs/Shang, Hyndman - 2017 - Grouped Functional Time Series Forecasting An Application to Age-Specific Mortality Rates.pdf:pdf},
  isbn          = {6126125053},
  keywords      = {Bottom-up,Forecast reconciliation,Hierarchical time series forecasting,Japanese mortality database,Optimal combination},
  publisher     = {Taylor {\&} Francis},
}

@Book{VanErven2014,
  title     = {Game-Theoretically Optimal reconciliation of contemporaneous hierarchical time series forecasts},
  year      = {2014},
  author    = {{Van Erven}, Tim and Cugliari, Jairo},
  editor    = {Antoniadis, A and Brossat, X and Poggi, J M},
  isbn      = {9783319187310},
  abstract  = {In hierarchical time series (HTS) forecasting, the hierarchical relation be- tween multiple time series is exploited to make better forecasts. This hierarchical relation implies one or more aggregate consistency constraints that the series are known to satisfy. Many existing approaches, like for example bottom-up or top- down forecasting, therefore attempt to achieve this goal in a way that guarantees that the forecasts will also be aggregate consistent. We propose to split the problem of HTS into two independent steps: first one comes up with the best possible fore- casts for the time series without worrying about aggregate consistency; and then a reconciliation procedure is used to make the forecasts aggregate consistent. We introduce a Game-Theoretically OPtimal (GTOP) reconciliation method, which is guaranteed to only improve any given set of forecasts. This opens up new possibil- ities for constructing the forecasts. For example, it is not necessary to assume that bottom-level forecasts are unbiased, and aggregate forecasts may be constructed by regressing both on bottom-level forecasts and on other covariates that may only be available at the aggregate level. We illustrate the benefits of our approach both on simulated data and on real electricity consumption data.},
  booktitle = {Spinger Lecture Notes in Statistics. Paris: Springer,},
  doi       = {10.1007/978-3-319-18732-7_15},
  file      = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Erven, Cugliari - 2014 - Game-Theoretically Optimal reconciliation of contemporaneous hierarchical time series forecasts.pdf:pdf},
  issn      = {21977186},
  pages     = {297--317},
}

@Article{HynEtAl2011,
  author    = {Hyndman, Rob J. and Ahmed, Roman A. and Athanasopoulos, George and Shang, Han Lin},
  title     = {Optimal combination forecasts for hierarchical time series},
  journal   = {Computational Statistics and Data Analysis},
  year      = {2011},
  volume    = {55},
  number    = {9},
  pages     = {2579--2589},
  abstract  = {In many applications, there are multiple time series that are hierarchically organized and can be aggregated at several different levels in groups based on products, geography or some other features. We call these "hierarchical time series". They are commonly forecast using either a "bottom-up" or a "top-down" method. In this paper we propose a new approach to hierarchical forecasting which provides optimal forecasts that are better than forecasts produced by either a top-down or a bottom-up approach. Our method is based on independently forecasting all series at all levels of the hierarchy and then using a regression model to optimally combine and reconcile these forecasts. The resulting revised forecasts add up appropriately across the hierarchy, are unbiased and have minimum variance amongst all combination forecasts under some simple assumptions. We show in a simulation study that our method performs well compared to the top-down approach and the bottom-up method. We demonstrate our proposed method by forecasting Australian tourism demand where the data are disaggregated by purpose of travel and geographical region. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
  doi       = {10.1016/j.csda.2011.03.006},
  isbn      = {0167-9473},
  keywords  = {Bottom-up forecasting,Combining forecasts,GLS regression,Hierarchical forecasting,Reconciling forecasts,Top-down forecasting},
  publisher = {Elsevier B.V.},
}

@Article{WicEtAl2019,
  author    = {Wickramasuriya, Shanika L and Athanasopoulos, George and Hyndman, Rob J},
  title     = {Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization},
  journal   = {Journal of the American Statistical Association},
  year      = {2018},
  volume    = {1459},
  pages     = {1--45},
  issn      = {0162-1459},
  abstract  = {AbstractLarge collections of time series often have aggregation constraints due to product or geographical groupings. The forecasts for the most disaggregated series are usually required to add-up exactly to the forecasts of the aggregated series, a constraint we refer to as â€œcoherenceâ€. Forecast reconciliation is the process of adjusting forecasts to make them coherent. The reconciliation algorithm proposed by Hyndman et al. (2011) is based on a generalized least squares estimator that requires an estimate of the covariance matrix of the coherency errors (i.e., the errors that arise due to incoherence). We show that this matrix is impossible to estimate in practice due to identifiability conditions. We propose a new forecast reconciliation approach that incorporates the information from a full covariance matrix of forecast errors in obtaining a set of coherent forecasts. Our approach minimizes the mean squared error of the coherent forecasts across the entire collection of time series under the assumption of unbiasedness. The minimization problem has a closed form solution. We make this solution scalable by providing a computationally efficient representation. We evaluate the performance of the proposed method compared to alternative methods using a series of simulation designs which take into account various features of the collected time series. This is followed by an empirical application using Australian domestic tourism data. The results indicate that the proposed method works well with artificial and real data.},
  doi       = {10.1080/01621459.2018.1448825},
  file      = {:C$\backslash$:/Users/Puwasala/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickramasuriya, Athanasopoulos, Hyndman - 2018 - Optimal forecast reconciliation for hierarchical and grouped time series through trace.pdf:pdf},
  keywords  = {Aggregation,Australian tourism,Coherent forecasts,contemporaneous error correlation,forecast combinations,spatial correlations},
  publisher = {Taylor {\&} Francis},
}

@Article{HK08,
  title = {Automatic time series forecasting: the forecast package for {R}},
  author = {Rob J Hyndman and Yeasmin Khandakar},
  year = {2008},
  number = {3},
  pages = {1--22},
  volume = {26},
  journal = {Journal of Statistical Software},
}

@Manual{Rforecast,
  title = {forecast: Forecasting Functions for Time Series and Linear Models},
  year = {2019},
  author = {Rob J Hyndman and George Athanasopoulos and Christoph Bergmeir and Gabriel Caceres and Leanne Chhay and Mitchell O'Hara-Wild and Fotios Petropoulos and Slava Razbash and Earo Wang and Farah Yasmeen and {R Core Team} and Ross Ihaka and Daniel Reid and David Shaub and Yuan Tang and Zhenyu Zhou},
  url = {https://CRAN.R-project.org/package=forecast},
  note = {Version 8.5},
}

@Book{expsmooth08,
  title = {Forecasting with exponential smoothing: the state space approach},
  author = {Rob J Hyndman and Anne B Koehler and J Keith Ord and Ralph D Snyder},
  year = {2008},
  publisher = {Springer-Verlag},
  address = {Berlin},
}

@misc{ABS2015,
  author = {{Australian Bureau of Statistics}},
  year = 2015,
  title = {Australian System of National Accounts: Concepts, Sources and Methods},
  note = {Cat 5216.0},
}
@misc{ABS2018,
author = {{Australian Bureau of Statistics}},
note = {Cat 5206.0},
title = {Australian National Accounts: National Income, Expenditure and Product},
year = {2018}
}
